{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing all the libraries required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "!pip install -q -U keras-tuner\n",
    "import kerastuner as kt\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers,models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout,Conv2D, MaxPooling2D, ZeroPadding2D,Dropout\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2379,
     "status": "ok",
     "timestamp": 1618413071744,
     "user": {
      "displayName": "Alexandru-Adonis Neagu",
      "photoUrl": "",
      "userId": "17990903344688168727"
     },
     "user_tz": -60
    },
    "id": "D2wSv5CUV81x",
    "outputId": "b1ba518f-248d-4aa9-f811-c6b22aca75c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Image data geerator for data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 2373,
     "status": "ok",
     "timestamp": 1618413071745,
     "user": {
      "displayName": "Alexandru-Adonis Neagu",
      "photoUrl": "",
      "userId": "17990903344688168727"
     },
     "user_tz": -60
    },
    "id": "ByjfIvlLV815"
   },
   "outputs": [],
   "source": [
    "img_width, img_height = 224, 224\n",
    "TrainingImagePath = 'D:/University 3rd year/Artificial Intelligence and Robotics/Assigment/Gender dataset/Training'\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2724,
     "status": "ok",
     "timestamp": 1618413072099,
     "user": {
      "displayName": "Alexandru-Adonis Neagu",
      "photoUrl": "",
      "userId": "17990903344688168727"
     },
     "user_tz": -60
    },
    "id": "xUYDcj2KV815",
    "outputId": "17c7da4b-f84a-44ef-f0ec-25b3edddf40f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37608 images belonging to 2 classes.\n",
      "Found 9401 images belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'female': 0, 'male': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.1,\n",
    "        validation_split=0.2,\n",
    "        rotation_range=5,\n",
    "        horizontal_flip=True)\n",
    " \n",
    "\n",
    "# Generating the Training Data\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "        TrainingImagePath,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        subset='training',\n",
    "        class_mode='binary')\n",
    " \n",
    " \n",
    "# Generating the Testing Data\n",
    "test_set = train_datagen.flow_from_directory(\n",
    "        TrainingImagePath,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        subset = 'validation',\n",
    "        class_mode='binary')\n",
    " \n",
    "# Printing class labels for each face\n",
    "test_set.class_indices\n",
    "#training_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing a pre-trained model from keras using the weights from imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 3076,
     "status": "ok",
     "timestamp": 1618413072460,
     "user": {
      "displayName": "Alexandru-Adonis Neagu",
      "photoUrl": "",
      "userId": "17990903344688168727"
     },
     "user_tz": -60
    },
    "id": "k7Jl3a46V816"
   },
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "base_model=tf.keras.applications.ResNet50(\n",
    "    include_top=False,\n",
    "    input_shape=input_shape,\n",
    "    weights=\"imagenet\"\n",
    "\n",
    ")\n",
    "\n",
    "for layer in base_model.layers:\n",
    "        layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tunning the base model by createing the top layers required for training on this dataset useing keras tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3073,
     "status": "ok",
     "timestamp": 1618413072461,
     "user": {
      "displayName": "Alexandru-Adonis Neagu",
      "photoUrl": "",
      "userId": "17990903344688168727"
     },
     "user_tz": -60
    },
    "id": "gZvyyfOQV816",
    "outputId": "de6e95ff-fc87-42ef-fc18-52c712fb4ce7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    num_classes = 2\n",
    "    dropout_rate_choice = hp.Float('rate', 0, .2, step=.1, default=.2)\n",
    "    optimizer1=hp.Choice('optimizer1', values=['adam', 'adagrad', 'SGD'])\n",
    "    \n",
    "    # Conditional for each optimizer\n",
    "    if optimizer1 == 'adam':\n",
    "        optimization = tf.keras.optimizers.Adam(hp.Float('learning_rate', 1e-5, 1e-2, sampling='LOG', default=1e-3))\n",
    "    elif optimizer1 == 'adagrad':\n",
    "        optimization = tf.keras.optimizers.Adagrad(hp.Float('learning_rate', 1e-5, 1e-2, sampling='LOG', default=1e-3))\n",
    "    elif optimizer1 == 'SGD':\n",
    "        optimization = tf.keras.optimizers.SGD(hp.Float('learning_rate', 1e-5, 1e-2, sampling='LOG', default=1e-2))\n",
    "        \n",
    "\n",
    "                        \n",
    "    base_input=base_model.layers[0].input\n",
    "    base_output=base_model.layers[-1].output\n",
    "    \n",
    "\n",
    "    final_output=layers.Conv2D(hp.Int('units_base', min_value=32, max_value=512, step=32, default=128), kernel_size=(3,3), padding=\"same\",kernel_regularizer=l2(hp.Float('regularizarer_rate_', 1e-5, 1e-2, sampling='LOG', default=1e-3)))(base_output)\n",
    "    final_output=layers.BatchNormalization()(final_output)\n",
    "    final_output=tf.keras.layers.ReLU()(final_output)\n",
    "    \n",
    "    for i in range(hp.Int('num_layers_conv2d', 1, 2)):  # adding variation of layers.\n",
    "         final_output=layers.Conv2D(hp.Int('units_conv2d_'+str(i), min_value=32, max_value=512, step=32, default=128), kernel_size=(3,3), padding=\"same\",kernel_regularizer=l2(hp.Float('regularizarer_rate_', 1e-5, 1e-2, sampling='LOG', default=1e-3)))(final_output)\n",
    "         final_output=layers.BatchNormalization()(final_output)\n",
    "         final_output=tf.keras.layers.ReLU()(final_output)\n",
    "\n",
    "    final_output=layers.GlobalMaxPooling2D(data_format='channels_last')(final_output)\n",
    "    \n",
    "    final_output=layers.Dropout(rate=dropout_rate_choice)(final_output)\n",
    "    final_output=layers.Flatten()(final_output)\n",
    "\n",
    "  \n",
    "    for i in range(hp.Int('num_layers_dense', 1, 2)):  # adding variation of layers.\n",
    "         final_output=layers.Dense(hp.Int('units_dense_'+str(i), min_value=32, max_value=512, step=32, default=128),kernel_regularizer=l2(0.0001))(final_output)\n",
    "         final_output=layers.BatchNormalization()(final_output)\n",
    "         final_output=tf.keras.layers.ReLU()(final_output)\n",
    "\n",
    "    final_output=layers.Dense(num_classes,activation='sigmoid')(final_output)\n",
    "\n",
    "\n",
    "    new_model=tf.keras.Model(inputs=base_input,outputs=final_output)\n",
    "    new_model.compile(optimizer=optimization, loss=tf.keras.losses.SparseCategoricalCrossentropy(),metrics=['accuracy'])\n",
    "    new_model.summary()\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate the tuner and perform hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 7, 7, 128)    2359424     conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 7, 7, 128)    512         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 7, 7, 128)    0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 7, 7, 128)    147584      re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 7, 7, 128)    512         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 7, 7, 128)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d (GlobalMax (None, 128)          0           re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           global_max_pooling2d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 128)          0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          16512       flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128)          512         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 128)          0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            258         re_lu_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 26,113,026\n",
      "Trainable params: 2,524,546\n",
      "Non-trainable params: 23,588,480\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_loss',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     project_name='gender_kt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 56m 19s]\n",
      "val_loss: 0.5543585419654846\n",
      "\n",
      "Best val_loss So Far: 0.15341542661190033\n",
      "Total elapsed time: 11h 18m 13s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(training_set ,validation_data=test_set, epochs=10,callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model and saveing the it at the and of each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 7, 7, 96)     1769568     conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 7, 7, 96)     384         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 7, 7, 96)     0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 7, 7, 160)    138400      re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 7, 7, 160)    640         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 7, 7, 160)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 7, 7, 320)    461120      re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 7, 7, 320)    1280        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 7, 7, 320)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d (GlobalMax (None, 320)          0           re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 320)          0           global_max_pooling2d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 320)          0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 192)          61632       flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 192)          768         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 192)          0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           6176        re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32)           128         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 32)           0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            66          re_lu_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 26,027,874\n",
      "Trainable params: 2,438,562\n",
      "Non-trainable params: 23,589,312\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1175/1175 [==============================] - 342s 288ms/step - loss: 0.3224 - accuracy: 0.8986 - val_loss: 0.1999 - val_accuracy: 0.9550\n",
      "Epoch 2/50\n",
      "1175/1175 [==============================] - 341s 291ms/step - loss: 0.2139 - accuracy: 0.9459 - val_loss: 0.1960 - val_accuracy: 0.9538\n",
      "Epoch 3/50\n",
      "1175/1175 [==============================] - 344s 293ms/step - loss: 0.1944 - accuracy: 0.9562 - val_loss: 0.2064 - val_accuracy: 0.9505\n",
      "Epoch 4/50\n",
      "1175/1175 [==============================] - 342s 291ms/step - loss: 0.1816 - accuracy: 0.9576 - val_loss: 0.1693 - val_accuracy: 0.9619\n",
      "Epoch 5/50\n",
      "1175/1175 [==============================] - 341s 291ms/step - loss: 0.1703 - accuracy: 0.9627 - val_loss: 0.1687 - val_accuracy: 0.9614\n",
      "Epoch 6/50\n",
      "1175/1175 [==============================] - 347s 295ms/step - loss: 0.1634 - accuracy: 0.9632 - val_loss: 0.1612 - val_accuracy: 0.9646\n",
      "Epoch 7/50\n",
      "1175/1175 [==============================] - 361s 307ms/step - loss: 0.1509 - accuracy: 0.9684 - val_loss: 0.1634 - val_accuracy: 0.9644\n",
      "Epoch 8/50\n",
      "1175/1175 [==============================] - 352s 300ms/step - loss: 0.1416 - accuracy: 0.9695 - val_loss: 0.1622 - val_accuracy: 0.9633\n",
      "Epoch 9/50\n",
      "1175/1175 [==============================] - 362s 308ms/step - loss: 0.1347 - accuracy: 0.9703 - val_loss: 0.1644 - val_accuracy: 0.9615\n",
      "Epoch 10/50\n",
      "1175/1175 [==============================] - 349s 297ms/step - loss: 0.1330 - accuracy: 0.9710 - val_loss: 0.1646 - val_accuracy: 0.9615\n",
      "Epoch 11/50\n",
      "1175/1175 [==============================] - 351s 298ms/step - loss: 0.1226 - accuracy: 0.9736 - val_loss: 0.1824 - val_accuracy: 0.9517\n",
      "Epoch 12/50\n",
      "1175/1175 [==============================] - 352s 299ms/step - loss: 0.1213 - accuracy: 0.9764 - val_loss: 0.1583 - val_accuracy: 0.9637\n",
      "Epoch 13/50\n",
      "1175/1175 [==============================] - 351s 299ms/step - loss: 0.1147 - accuracy: 0.9761 - val_loss: 0.1585 - val_accuracy: 0.9622\n",
      "Epoch 14/50\n",
      "1175/1175 [==============================] - 358s 304ms/step - loss: 0.1112 - accuracy: 0.9781 - val_loss: 0.1897 - val_accuracy: 0.9535\n",
      "Epoch 15/50\n",
      "1175/1175 [==============================] - 349s 297ms/step - loss: 0.1072 - accuracy: 0.9796 - val_loss: 0.1728 - val_accuracy: 0.9586\n",
      "Epoch 16/50\n",
      "1175/1175 [==============================] - 346s 294ms/step - loss: 0.1091 - accuracy: 0.9788 - val_loss: 0.1594 - val_accuracy: 0.9605\n",
      "Epoch 17/50\n",
      "1175/1175 [==============================] - 339s 289ms/step - loss: 0.1051 - accuracy: 0.9798 - val_loss: 0.1720 - val_accuracy: 0.9594\n",
      "Epoch 18/50\n",
      "1175/1175 [==============================] - 338s 288ms/step - loss: 0.0981 - accuracy: 0.9822 - val_loss: 0.1672 - val_accuracy: 0.9590\n",
      "Epoch 19/50\n",
      "1175/1175 [==============================] - 346s 294ms/step - loss: 0.0945 - accuracy: 0.9839 - val_loss: 0.1902 - val_accuracy: 0.9581\n",
      "Epoch 20/50\n",
      "1175/1175 [==============================] - 347s 295ms/step - loss: 0.0971 - accuracy: 0.9817 - val_loss: 0.1660 - val_accuracy: 0.9574\n",
      "Epoch 21/50\n",
      "1175/1175 [==============================] - 360s 306ms/step - loss: 0.0949 - accuracy: 0.9843 - val_loss: 0.1939 - val_accuracy: 0.9595\n",
      "Epoch 22/50\n",
      "1175/1175 [==============================] - 350s 298ms/step - loss: 0.0955 - accuracy: 0.9825 - val_loss: 0.1656 - val_accuracy: 0.9636\n",
      "Epoch 23/50\n",
      "1175/1175 [==============================] - 346s 295ms/step - loss: 0.0904 - accuracy: 0.9853 - val_loss: 0.1925 - val_accuracy: 0.9592\n",
      "Epoch 24/50\n",
      "1175/1175 [==============================] - 363s 309ms/step - loss: 0.0894 - accuracy: 0.9859 - val_loss: 0.1739 - val_accuracy: 0.9544\n",
      "Epoch 25/50\n",
      "1175/1175 [==============================] - 344s 292ms/step - loss: 0.0884 - accuracy: 0.9863 - val_loss: 0.2108 - val_accuracy: 0.9454\n",
      "Epoch 26/50\n",
      "1175/1175 [==============================] - 341s 290ms/step - loss: 0.0858 - accuracy: 0.9866 - val_loss: 0.1645 - val_accuracy: 0.9569\n",
      "Epoch 27/50\n",
      "1175/1175 [==============================] - 338s 288ms/step - loss: 0.0854 - accuracy: 0.9867 - val_loss: 0.1874 - val_accuracy: 0.9606\n",
      "Epoch 28/50\n",
      "1175/1175 [==============================] - 337s 287ms/step - loss: 0.0856 - accuracy: 0.9872 - val_loss: 0.1722 - val_accuracy: 0.9595\n",
      "Epoch 29/50\n",
      "1175/1175 [==============================] - 355s 302ms/step - loss: 0.0836 - accuracy: 0.9864 - val_loss: 0.1950 - val_accuracy: 0.9550\n",
      "Epoch 30/50\n",
      "1175/1175 [==============================] - 354s 301ms/step - loss: 0.0837 - accuracy: 0.9862 - val_loss: 0.1818 - val_accuracy: 0.9540\n",
      "Epoch 31/50\n",
      "1175/1175 [==============================] - 347s 295ms/step - loss: 0.0820 - accuracy: 0.9881 - val_loss: 0.1706 - val_accuracy: 0.9627\n",
      "Epoch 32/50\n",
      "1175/1175 [==============================] - 342s 291ms/step - loss: 0.0814 - accuracy: 0.9875 - val_loss: 0.1990 - val_accuracy: 0.9547\n",
      "Epoch 33/50\n",
      "1175/1175 [==============================] - 341s 291ms/step - loss: 0.0820 - accuracy: 0.9873 - val_loss: 0.2107 - val_accuracy: 0.9616\n",
      "Epoch 34/50\n",
      "1175/1175 [==============================] - 337s 287ms/step - loss: 0.0809 - accuracy: 0.9882 - val_loss: 0.2194 - val_accuracy: 0.9638\n",
      "Epoch 35/50\n",
      "1175/1175 [==============================] - 342s 291ms/step - loss: 0.0832 - accuracy: 0.9872 - val_loss: 0.2494 - val_accuracy: 0.9533\n",
      "Epoch 36/50\n",
      "1175/1175 [==============================] - 342s 291ms/step - loss: 0.0820 - accuracy: 0.9871 - val_loss: 0.1810 - val_accuracy: 0.9573\n",
      "Epoch 37/50\n",
      "1175/1175 [==============================] - 341s 290ms/step - loss: 0.0782 - accuracy: 0.9889 - val_loss: 0.1854 - val_accuracy: 0.9588\n",
      "Epoch 38/50\n",
      "1175/1175 [==============================] - 337s 287ms/step - loss: 0.0783 - accuracy: 0.9885 - val_loss: 0.1898 - val_accuracy: 0.9632\n",
      "Epoch 39/50\n",
      "1175/1175 [==============================] - 338s 288ms/step - loss: 0.0768 - accuracy: 0.9896 - val_loss: 0.1746 - val_accuracy: 0.9603\n",
      "Epoch 40/50\n",
      "1175/1175 [==============================] - 344s 293ms/step - loss: 0.0780 - accuracy: 0.9884 - val_loss: 0.2104 - val_accuracy: 0.9611\n",
      "Epoch 41/50\n",
      "1175/1175 [==============================] - 346s 295ms/step - loss: 0.0798 - accuracy: 0.9882 - val_loss: 0.1950 - val_accuracy: 0.9595\n",
      "Epoch 42/50\n",
      "1175/1175 [==============================] - 341s 290ms/step - loss: 0.0740 - accuracy: 0.9905 - val_loss: 0.1958 - val_accuracy: 0.9620\n",
      "Epoch 43/50\n",
      "1175/1175 [==============================] - 340s 289ms/step - loss: 0.0788 - accuracy: 0.9881 - val_loss: 0.2169 - val_accuracy: 0.9595\n",
      "Epoch 44/50\n",
      "1175/1175 [==============================] - 338s 287ms/step - loss: 0.0777 - accuracy: 0.9893 - val_loss: 0.2056 - val_accuracy: 0.9585\n",
      "Epoch 45/50\n",
      "1175/1175 [==============================] - 337s 287ms/step - loss: 0.0750 - accuracy: 0.9890 - val_loss: 0.2250 - val_accuracy: 0.9498\n",
      "Epoch 46/50\n",
      "1175/1175 [==============================] - 338s 287ms/step - loss: 0.0759 - accuracy: 0.9896 - val_loss: 0.2015 - val_accuracy: 0.9557\n",
      "Epoch 47/50\n",
      "1175/1175 [==============================] - 337s 287ms/step - loss: 0.0755 - accuracy: 0.9901 - val_loss: 0.2093 - val_accuracy: 0.9578\n",
      "Epoch 48/50\n",
      "1175/1175 [==============================] - 474s 403ms/step - loss: 0.0734 - accuracy: 0.9911 - val_loss: 0.1930 - val_accuracy: 0.9605\n",
      "Epoch 49/50\n",
      "1175/1175 [==============================] - 395s 336ms/step - loss: 0.0747 - accuracy: 0.9906 - val_loss: 0.2173 - val_accuracy: 0.9538\n",
      "Epoch 50/50\n",
      "1175/1175 [==============================] - 346s 295ms/step - loss: 0.0748 - accuracy: 0.9906 - val_loss: 0.2001 - val_accuracy: 0.9578\n"
     ]
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "directory='Checkpoint'\n",
    "name='Model'\n",
    "saved = os.path.join(directory, name + \"-{epoch:02d}.h5\")\n",
    "callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=saved, monitor='val_loss', verbose=0, save_best_only=True,\n",
    "    save_weights_only=False, mode='min', save_freq='epoch'\n",
    ")\n",
    "history=model.fit(training_set,\n",
    "        epochs=50,\n",
    "        callbacks=callback,\n",
    "        steps_per_epoch=37608// batch_size,\n",
    "        validation_data=test_set,\n",
    "        validation_steps= 9401  // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 621
    },
    "executionInfo": {
     "elapsed": 107612,
     "status": "ok",
     "timestamp": 1618413177010,
     "user": {
      "displayName": "Alexandru-Adonis Neagu",
      "photoUrl": "",
      "userId": "17990903344688168727"
     },
     "user_tz": -60
    },
    "id": "SOnnBxsjV818",
    "outputId": "2eeaa723-1f04-4671-c622-c8be44f3c2fb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1.2])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,4.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Copy of Face_recogntion.ipynb",
   "provenance": [
    {
     "file_id": "1yNmCbe7kAs3BT2DENMtYGevOp9CaQxpb",
     "timestamp": 1618093254106
    }
   ]
  },
  "kernelspec": {
   "display_name": "Kernal_gpu",
   "language": "python",
   "name": "environment_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
