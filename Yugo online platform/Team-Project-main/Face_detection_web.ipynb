{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing all the libraires needed for importing the model and procesing the image from the web-cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from flask import request\n",
    "from flask import Flask, Blueprint\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opening the web-cam, preprocessing the images retrived, makeing predictions for each frame and choseing the class with the most correct predictionsÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [19/Apr/2021 19:05:39] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "Face_detector = Blueprint('Face_detector', __name__)\n",
    "\n",
    "@Face_detector.route('/')\n",
    "#Function that opens the camera and predict the face\n",
    "def face_prediction():\n",
    "\n",
    "    face_classifier =cv2.CascadeClassifier(r'C:/Users/Alexandru Neagu/Exercises/Team project/haarcascade_frontalface_default.xml')\n",
    "    classifier= load_model(r'C:/Users/Alexandru Neagu/Exercises/Team project/Face_recognition/Checkpoint/Model-10.h5')\n",
    "\n",
    "    class_labels=['Alexandru', 'Diana', 'Sebastian', 'Unknown']\n",
    "\n",
    "    freq=[0,0,0,0]\n",
    "\n",
    "    cap=cv2.VideoCapture(0)\n",
    "    cap.set(3, 640) # set video widht\n",
    "    cap.set(4, 480) # set video height\n",
    "\n",
    "    minW = 0.1*cap.get(3)\n",
    "    minH = 0.1*cap.get(4)\n",
    "\n",
    "    count=0\n",
    "    while True:\n",
    "        # Read the frame\n",
    "        _, img = cap.read()\n",
    "        count+=1\n",
    "        labels = []\n",
    "        # Detect the faces\n",
    "        faces = face_classifier.detectMultiScale( \n",
    "            img,\n",
    "            scaleFactor = 1.2,\n",
    "            minNeighbors = 5,\n",
    "            minSize = (int(minW), int(minH)),\n",
    "           )\n",
    "        # Draw the rectangle around each face\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "            roi_gray = img[y:y+h,x:x+w]\n",
    "            \n",
    "       \n",
    "            #Get the image to the right dimension   \n",
    "            cropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_gray, (224, 224)), -1), 0)\n",
    "            preds = classifier.predict(cropped_img)\n",
    "            label=class_labels[np.argmax(preds)]\n",
    "            #Createing a list with the freaquances of each prediction\n",
    "            freq[class_labels.index(label)]+=1\n",
    "            label_position = (x,y)\n",
    "            cv2.putText(img,label,label_position,cv2.FONT_HERSHEY_SIMPLEX,2,(0,255,0),3)\n",
    "       \n",
    "            print(\"\\n\\n\")\n",
    "        # Display\n",
    "        cv2.imshow('img', img)\n",
    "        # Stop if escape key is pressed\n",
    "        k = cv2.waitKey(30) & 0xff\n",
    "        if k==27:\n",
    "            break\n",
    "        elif count >= 20: # Take 20 face sample and stop video\n",
    "            break\n",
    "    # Release the VideoCapture object\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    #Return the most predicted class\n",
    "    return class_labels[freq.index(max(freq))]\n",
    "    \n",
    "\n",
    "def restartkernel() :\n",
    "    IPython.Application.instance().kernel.do_shutdown(True) #automatically restarts kernel\n",
    "    return \"Kernal restarted\"\n",
    "    #Function that shuts down th\n",
    "    e server\n",
    "def shutdown_server():\n",
    "    func = request.environ.get('werkzeug.server.shutdown')\n",
    "    if func is None:\n",
    "        raise RuntimeError('Not running with the Werkzeug Server')\n",
    "    func()\n",
    "    \n",
    "@Face_detector.route('/restart', methods=['GET'])\n",
    "def shutdown():\n",
    "    shutdown_server()\n",
    "    restartkernel()\n",
    "    return 'Server shutting down...'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "     \n",
    "    #Running the appication on the server\n",
    "    app = Flask(__name__)\n",
    "    app.register_blueprint(Face_detector, url_prefix='/')\n",
    "    app.run()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kernal_gpu",
   "language": "python",
   "name": "environment_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
